================================================================================
文献综述 — 视障用户触觉导航系统
================================================================================
编写日期: 2026年2月19日
项目: haptic-nav-system (iOS ARKit LiDAR + ESP32-S3 BLE 触觉反馈)

目的: 从相关研究中提取可用于改进我们系统的方法、技术和设计思路，
涵盖障碍物检测(B2)、导航仲裁(Step 3)、触觉编码(Step 4)及整体用户体验。

================================================================================
论文 1
================================================================================
标题:   Characterizing and Predicting Engagement of Blind and Low-Vision
        People with an Audio-Based Navigation App
        (视障用户对基于音频导航App的参与度特征分析与预测)
作者:   Liu, Hernandez, Gonzalez-Franco, Maselli, Ofek, Lindeman, Cutrell
发表:   CHI 2022 (Late Breaking Work)
DOI:    10.1145/3491101.3519862
来源:   Microsoft Research (Soundscape 项目)

摘要:
研究了 4,700+ 名视障/低视力(BLV)用户使用 Microsoft Soundscape 的参与度模式。
Soundscape 是一款基于音频的户外导航 App，通过 3D 空间音频线索进行寻路引导。
使用机器学习模型预测用户参与度变化。

主要方法与发现:
- 参与度指标: 会话频率、时长、功能使用模式
- 机器学习模型 (Random Forest, XGBoost) 可预测用户是否会持续使用
- 关键发现: 首几次使用中探索"设置音频信标"功能的用户更可能成为长期用户
- 3D 空间音频线索(双耳音频)显著提高了空间感知能力

与我们项目的关联:
- **用户参与度洞察**: 早期使用中简单可靠的反馈对用户留存至关重要
  —— 我们的触觉反馈必须让用户一上手就能理解
- **多模态反馈**: Soundscape 用音频，我们用触觉，两者都受益于方向编码
  (左/右强度映射)
- **设计原则**: 允许用户在"探索模式"和"导航模式"间切换
  —— 考虑增加"扫描模式"仅用 LiDAR 探测周围环境
- **评估指标**: 可追踪振动反馈准确率作为参与度指标

================================================================================
论文 2
================================================================================
标题:   All the Way There and Back: Inertial-Based, Phone-in-Pocket Indoor
        Wayfinding and Backtracking Apps for Blind Travelers
        (基于惯性传感器的手机口袋内室内寻路与回溯导航App)
作者:   Tsai, Elyasi, Ren, Manduchi
发表:   ACM Transactions on Accessible Computing, 2024
DOI:    10.1145/3696005

摘要:
两个 iOS App，仅使用惯性和磁力传感器(加速度计、陀螺仪、磁力计)进行室内导航
—— 不需要摄像头、不需要 BLE 信标、不需要任何基础设施改造。用户将手机放在口袋里，
通过 Apple Watch 交互。Wayfinding App 沿预定路线导航；Backtracking App 记录并
反向引导用户走回的路线。

主要方法与发现:
- **行人航迹推算 (PDR)**: 步频检测 + 步长估计 + 磁力计/陀螺仪融合航向
- **航向校正**: 利用楼层平面图的已知走廊方向，通过粒子滤波器校正磁力计漂移
- **转弯检测**: 基于陀螺仪角速度峰值检测
- **手机放口袋**: 无需手持手机 —— 对需要双手自由(白手杖 + 导盲犬)的视障用户
  是重要的用户体验优势
- **智能手表作为 UI**: Apple Watch 提供语音输出 + 触觉轻拍用于逐步导航指令
- **回溯功能**: 记录惯性轨迹，然后反转左右指令引导用户返回
- 测试: 7 名视障参与者，高任务完成率，低偏差

与我们项目的关联:
- **智能手表作为触觉输出**: 我们目前使用 ESP32 手腕设备，但 Apple Watch 内置
  触觉引擎可作为未来替代/补充方案
- **手机放口袋模式**: 我们的系统需要手持手机以使用 LiDAR，但纯 GPS 宏观导航
  时可支持口袋模式
- **航向估计**: 他们的 PDR 航向校正方法可补充我们的指南针航向，提高室内方向
  估计稳定性
- **转向指令格式**: 他们使用时钟方向(如"2点钟方向") —— 我们可在触觉模式中
  编码类似的方向粒度
- **回溯功能**: 对我们的用户很实用 —— 记录去程路线并提供触觉引导返回

================================================================================
论文 3
================================================================================
标题:   A Smartphone-Based Mobility Assistant Using Depth Imaging for
        Visually Impaired and Blind
        (基于深度成像的智能手机视障移动辅助系统)
作者:   See, Sasing, Advincula
发表:   Applied Sciences 12(6):2802, 2022
DOI:    10.3390/app12062802

摘要:
一款使用手机深度摄像头(TrueDepth/LiDAR)检测障碍物的智能手机 App。从深度帧中
采样 23 个特定坐标点的深度值，分析后判断障碍物的存在和距离，通过音频反馈告警。

主要方法与发现:
- **23 点深度采样**: 不处理整个深度缓冲区，而是在左、中、右区域的多个高度上
  采样 23 个战略性放置的坐标点
- **分区检测**: 将视场分为 3 个水平区域(左、中、右)和 3 个垂直区域(上、中、下)
- **阈值分类**: 按距离将障碍物分为不同危险等级，配对应音频告警
- **纯手机方案**: 不需要额外硬件
- 测试结果: 2m 范围内 93% 障碍物检测准确率
- 可用性评估: SUS 分数 > 80 (高满意度)

与我们项目的关联:
- **稀疏采样策略**: 我们的 16×16 网格(256 cells)远密于他们的 23 个点
  —— 验证了即使稀疏深度采样也能有效工作
- **分区方法**: 他们的左/中/右区域直接对应我们的触觉左/右电机编码
- **验证**: 确认了智能手机深度摄像头可用于实时视障障碍物检测
- **音频补充**: 他们用音频，我们用触觉 —— 考虑为关键危险(如楼梯警告)添加
  可选音频提示
- **我们的优势**: 16×16 网格 + 第10百分位提供了远高于 23 个离散点的
  空间分辨率和噪声鲁棒性

================================================================================
论文 4
================================================================================
标题:   MAIDR Meets AI: Exploring Multimodal LLM-Based Data Visualization
        Interpretation by and with Blind and Low-Vision Users
        (MAIDR 遇上 AI: 探索视障用户的多模态 LLM 数据可视化解读)
作者:   (多位)
发表:   ASSETS 2024
DOI:    10.1145/3663548.3675660

注意: 该论文关于使用 LLM 的无障碍数据可视化，而非触觉导航或障碍物检测。
探讨视障用户如何通过多模态 AI 描述与图表交互。虽然不直接适用于我们的障碍物
检测流水线，但提供了无障碍界面设计的洞察。

与我们项目的关联:
- **多模态无障碍**: 强化了信息应通过多种通道传达的原则
  (我们的系统: 触觉 + 可选音频)
- **以用户为中心的设计**: 强调在设计迭代中纳入视障用户参与
- 对我们障碍物检测系统的直接技术适用性有限

================================================================================
论文 5
================================================================================
标题:   A Lightweight Approach to Localization for Blind and Visually
        Impaired Travelers
        (面向视障旅行者的轻量化定位方法)
作者:   Crabb, Cheraghi, Coughlan
发表:   Sensors 23(5):2701, 2023
DOI:    10.3390/s23052701

摘要:
提出一种轻量化的室内定位系统，不需要基础设施改造(无信标、无 WiFi 指纹)。
结合手机摄像头的视觉特征和惯性传感器来估计建筑内的位置。

主要方法与发现:
- **视觉惯性里程计**: 结合摄像头特征跟踪和 IMU 数据进行位置估计
- **轻量化设计**: 在标准智能手机上运行，无需云端处理
- **无基础设施要求**: 不同于 BLE 信标系统，在任何建筑中均可工作
- **地图匹配**: 将估计轨迹与已知楼层平面几何对齐以校正漂移
- 专为无障碍设计 —— 经视障参与者测试

与我们项目的关联:
- **室内定位**: 我们的系统目前依赖 Google Maps GPS，室内无法使用
  —— 该方法可将我们的系统扩展到室内场景
- **视觉惯性融合**: ARKit 已经实现了视觉惯性里程计；我们可利用 ARKit 的
  世界跟踪功能进行室内位置估计
- **地图匹配漂移校正**: 可用于改善我们导航流水线中的航向精度
- **与我们 LiDAR 的互补**: LiDAR 处理微观障碍物，该方法处理宏观位置定位

================================================================================
论文 6
================================================================================
标题:   (无法检索 — DOI 10.1145/3308561.3353788 来自 ASSETS 2019 会议论文集，
        通过可用搜索渠道未能解析为特定论文标题)
发表:   ASSETS 2019
DOI:    10.1145/3308561.3353788

注意: 该 DOI 属于 ASSETS 2019 会议论文集 (10.1145/3308561)。无法获取具体内容。
如果原始意图是引用触觉反馈袖套论文，请参见下方补充条目。

--- 补充: 触觉反馈袖套 (可能的目标引用) ---
标题:   Obstacle Avoidance for Blind People Using a 3D Camera and a Haptic
        Feedback Sleeve
        (使用 3D 摄像头和触觉反馈袖套的视障障碍物规避)
作者:   Zuschlag 等
发表:   arXiv:2201.04453, 2022

摘要:
将 Intel RealSense 3D 深度摄像头与穿戴在前臂的触觉反馈袖套结合。将深度图像
映射到 2D 振动电机阵列上，让用户通过触觉获得障碍物的空间"图像"。

主要方法与发现:
- **深度到振动映射**: 深度摄像头输出 → 前臂袖套上的 2D 振动电机网格
- **电机阵列布局**: 多个振动电机按行列排列在前臂上；越近的障碍物 = 越强的振动
- **单电机识别**: 98.6% 准确率识别单个电机振动模式
- **多电机识别**: 70% 准确率识别多方向多电机模式
- **光照无关**: 在完全黑暗中工作(红外深度摄像头)
- **用户测试**: 所有参与者在黑暗中完成障碍物课程；多次运行后性能提升

与我们项目的关联:
- **直接类比**: 我们使用 2 个电机(左/右手腕)，他们使用完整的 2D 阵列
  —— 证明了空间触觉映射的可行性
- **深度到振动流水线**: 验证了我们将深度网格数据转换为电机强度的方法
- **关键洞察**: 即使只有 2 个电机，我们也能编码左/右障碍物方向 + 与距离
  成正比的强度
- **多电机模式**: 如果未来扩展到更多电机，他们的 2D 阵列范式展示了如何将
  网格列映射到电机位置
- **性能随练习提高**: 对用户研究设计很重要 —— 用户需要训练期

================================================================================
论文 7
================================================================================
标题:   Assisting the Visually Impaired: Obstacle Detection and Warning
        System by Acoustic Feedback
        (辅助视障者: 基于声学反馈的障碍物检测与预警系统)
作者:   Rodriguez, Mallofré, Andrade
发表:   Sensors 12(12):17476-17496, 2012
DOI:    10.3390/s121217476

摘要:
基于立体摄像头的障碍物检测系统，计算密集视差图，使用 RANSAC 估计地面平面，
并在极坐标网格中表示障碍物，通过声学反馈传达给视障用户。

主要方法与发现:
- **密集视差图**: 使用块匹配从立体摄像头对计算
- **RANSAC 地面平面估计**:
  1. 从视差图中随机采样 3 个点
  2. 拟合平面方程: ax + by + cz = d
  3. 计算内点数(平面距离阈值内的点)
  4. 重复 N 次迭代，保留最佳平面
  5. 应用时间滤波(指数移动平均)跨帧平滑地面平面估计
- **U-视差和 V-视差**: 视差图的列和行直方图，用于快速识别地面平面和垂直障碍物
- **极坐标网格表示**:
  - 将场景分为角度扇区(列)和距离环(行)
  - 每个单元格存储占用状态
  - 高效表示"什么在哪里"(相对于用户)
  - 自然映射到方向反馈(角度 → 左/右)
- **声学反馈**: 障碍物网格的声学化 —— 音高编码距离，立体声位移编码方向
- 室内外场景均可工作
- 嵌入式硬件上实时处理

与我们项目的关联:
*** 高度相关 — 多个方法可直接应用 ***
- **RANSAC 地面平面**: 可在我们的 16×16 深度网格上实现轻量版本。
  利用 256 个深度值 + ARKit 相机姿态，拟合地面平面，将高于地面的分类为
  障碍物、地面级的分类为安全。解决"地面误报"问题。
- **极坐标网格**: 我们的 16×16 笛卡尔网格可转换为以用户为中心的极坐标表示
  —— 角度扇区直接映射到左/右触觉电机
- **时间滤波**: 对深度网格跨帧应用指数移动平均以减少噪声和闪烁
- **U-视差概念**: 按列求和深度值可快速得到"每个方向的障碍物密度"指标
  —— 直接用于决定左/右电机强度
- **距离环**: 将深度网格行映射到距离带；最近的带触发最强触觉响应

================================================================================
论文 8
================================================================================
标题:   An Indoor Obstacle Detection System Using Depth Information and
        Region Growing
        (基于深度信息和区域生长的室内障碍物检测系统)
作者:   Huang, Hsieh, Yeh
发表:   Sensors 15(10):27116-27141, 2015
DOI:    10.3390/s151027116

摘要:
使用 Microsoft Kinect 深度传感器进行室内障碍物检测。核心创新是将 RANSAC 地面
移除与区域生长结合，分割并识别独立障碍物。

主要方法与发现:
- **深度图像采集**: Kinect 深度传感器 (640×480 深度图)
- **RANSAC 地面平面移除**:
  1. 使用 RANSAC 从深度图像估计地面平面
  2. 移除属于地面平面的所有点
  3. 剩余点为候选障碍物
  - 关键洞察: 地面和障碍物交界处有相似的深度值，使得简单阈值法不够用
    —— 必须显式移除地面
- **区域生长分割**:
  1. 地面移除后，在剩余深度区域放置种子点
  2. 区域生长通过添加具有相似深度值(阈值内)的相邻像素来扩展种子
  3. 每个生长区域 = 一个障碍物
  4. 过滤掉小区域(视为噪声)
- **连通域标记**: 区域生长的替代方案，用于分组障碍物像素，但在边界处效果较差
- **包围盒提取**: 每个分割出的障碍物获得一个包围盒，附带估计的位置和大小
- **语音播报**: 文字转语音反馈，描述障碍物位置(如"左侧有障碍物，1.5米")

与我们项目的关联:
*** 高度相关 — 地面移除 + 障碍物分割 ***
- **地面移除至关重要**: 确认简单深度阈值不够 —— 地面在深度图像下部显示为
  "近距离"物体。我们的 forwardCropRatio 部分解决了这个问题，但 RANSAC
  地面估计会更鲁棒。
- **网格上的区域生长**: 在 16×16 网格上进行阈值检测后，可用简单连通域分析
  将相邻"危险" cell 聚合为障碍物簇。这可以告诉我们:
  - 存在多少个独立障碍物
  - 每个障碍物的角度宽度(能否绕过?)
  - 每个障碍物的最近点
- **语音补充**: 他们的 TTS 方法可补充我们的触觉反馈，用于关键危险
  ("前方有楼梯"、"左侧有墙")
- **适配我们 16×16 网格的简化版本**:
  1. 从网格底部行估计地面(最大深度值)
  2. 将明显比预期地面深度更近的 cell 标记为障碍物
  3. 在 16×16 二值网格上运行 4-连通域标记
  4. 对每个连通域: 计算质心(方向)和最小深度(紧急程度)


================================================================================
综合分析: 我们系统中应实现的方法
================================================================================

优先级 1 — 立即实现 (Step 2: HazardResult)
-------------------------------------------
a) 垂直梯度 ΔV (论文 7, 8)
   - grid[r][c] - grid[r+1][c] → 检测台阶、路沿、落差
   - 大正值 ΔV = 地形向下突降(危险)
   - 大负值 ΔV = 地形向上突起(上台阶/墙基)

b) 水平梯度 ΔH (论文 7, 8)
   - grid[r][c] - grid[r][c+1] → 检测障碍物边缘、柱子
   - 帮助判断障碍物是否可以绕过

c) 列求和障碍物密度 (论文 7 — U-视差概念)
   - 按列求和"危险" cell → 每个方向的障碍物密度
   - 左半求和 vs 右半求和 → 哪个方向更安全
   - 直接映射到左/右电机强度

d) 时间平滑 (论文 7)
   - 跨帧指数移动平均: grid_smooth = α * grid_new + (1-α) * grid_old
   - 减少触觉输出的闪烁

优先级 2 — 下一轮迭代 (Step 2-3)
----------------------------------
e) 简易地面平面估计 (论文 7, 8)
   - 使用深度网格底部行作为地面参考
   - 或在 16×16 网格上做轻量 RANSAC (仅 256 个点，非常快)
   - 明显比地面平面更近的 cell = 障碍物

f) 连通域分析 (论文 8)
   - 二值网格(障碍/自由) → 4-连通域
   - 每个连通域 = 一个障碍物，附质心方向 + 最小深度
   - 可实现"左侧1.2米处有障碍物"类型的触觉编码

g) 自由空间/最安全方向 (论文 3, 7)
   - 找到"绿色" cell 最多的列范围 → 最安全行走方向
   - 编码为向安全方向的微妙触觉引导

优先级 3 — 未来增强
--------------------
h) 极坐标网格转换 (论文 7)
   - 将笛卡尔 16×16 转为极坐标表示，实现更自然的方向到电机映射

i) 室内定位 (论文 2, 5)
   - 利用 ARKit 世界跟踪进行室内导航
   - 添加回溯功能用于返程

j) 多模态反馈 (论文 1, 3, 8)
   - 为关键危险添加可选音频提示
   - 考虑将 Apple Watch 触觉作为补充输出

k) 用户参与度追踪 (论文 1)
   - 追踪使用模式以随时间改进系统
   - 为新用户设计校准期


================================================================================
参考文献 (按出现顺序)
================================================================================
[1] Liu, T. 等 (2022). Characterizing and Predicting Engagement of Blind
    and Low-Vision People with an Audio-Based Navigation App. CHI '22 Extended
    Abstracts. https://doi.org/10.1145/3491101.3519862

[2] Tsai, C.H. 等 (2024). All the Way There and Back: Inertial-Based,
    Phone-in-Pocket Indoor Wayfinding and Backtracking Apps for Blind
    Travelers. ACM TACCESS. https://doi.org/10.1145/3696005

[3] See, A.R., Sasing, B.G., Advincula, W.D. (2022). A Smartphone-Based
    Mobility Assistant Using Depth Imaging for Visually Impaired and Blind.
    Applied Sciences, 12(6), 2802. https://doi.org/10.3390/app12062802

[4] MAIDR Meets AI (2024). Exploring Multimodal LLM-Based Data Visualization
    Interpretation by and with Blind and Low-Vision Users. ASSETS '24.
    https://doi.org/10.1145/3663548.3675660

[5] Crabb, R., Cheraghi, S.A., Coughlan, J.M. (2023). A Lightweight Approach
    to Localization for Blind and Visually Impaired Travelers. Sensors, 23(5),
    2701. https://doi.org/10.3390/s23052701

[6] ASSETS 2019 论文 (DOI: 10.1145/3308561.3353788) — 无法检索。
    补充: Zuschlag 等 (2022). Obstacle Avoidance for Blind People Using a
    3D Camera and a Haptic Feedback Sleeve. arXiv:2201.04453.

[7] Rodriguez, A., Mallofré, A.C., Andrade, L. (2012). Assisting the Visually
    Impaired: Obstacle Detection and Warning System by Acoustic Feedback.
    Sensors, 12(12), 17476-17496. https://doi.org/10.3390/s121217476

[8] Huang, H.-C., Hsieh, C.-T., Yeh, C.-H. (2015). An Indoor Obstacle
    Detection System Using Depth Information and Region Growing. Sensors,
    15(10), 27116-27141. https://doi.org/10.3390/s151027116
